{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-27T00:01:03.128592Z",
     "start_time": "2024-05-27T00:00:59.917419Z"
    }
   },
   "source": [
    "from data_manager import Document, Vector\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "import json\n",
    "import pickle"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "stop_words = set([word.lower() for word in stopwords.words('english')])\n",
    "snowball_stemmer = SnowballStemmer('english')\n",
    "\n",
    "def process_text(text: str) -> dict[str, int]:\n",
    "    text = \"\".join(list(map(lambda c: \" \" if c in punctuation else c, text)))\n",
    "    words = [word.lower() for sentence in sent_tokenize(text) for word in word_tokenize(sentence)]\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    words = [snowball_stemmer.stem(word) for word in words]\n",
    "    return dict(FreqDist(words))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T00:01:08.493670Z",
     "start_time": "2024-05-27T00:01:08.486098Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "docs: list[Document] = []\n",
    "with open(\"data/RawDocuments.pickle\", \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            docs.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T00:01:33.297091Z",
     "start_time": "2024-05-27T00:01:10.713933Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "vectors: list[Vector] = []\n",
    "for i, doc in enumerate(docs):\n",
    "    vectors.append(Vector(doc.title, doc.question_id, process_text(doc.text)))"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"data/Documents.pickle\", \"wb\") as f:\n",
    "    for vec in vectors:\n",
    "        pickle.dump(vec, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T00:53:32.951058Z",
     "start_time": "2024-05-27T00:49:31.135994Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "initial_alphabet: dict[str, int] = {}\n",
    "word_count = 0\n",
    "for vec in vectors:\n",
    "    for word in vec.vector:\n",
    "        if word not in initial_alphabet:\n",
    "            initial_alphabet[word] = 1\n",
    "        else:\n",
    "            initial_alphabet[word] += 1\n",
    "        word_count += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T00:59:55.685214Z",
     "start_time": "2024-05-27T00:58:18.397642Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Different words in alphabet: {len(initial_alphabet)}\")\n",
    "print(f\"Total number of words: {word_count}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:00:02.333490Z",
     "start_time": "2024-05-27T01:00:02.313126Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different words in alphabet: 1655664\n",
      "Total number of words: 61054066\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_words_with_count_below_2(alphabet):\n",
    "    new_alphabet = {}\n",
    "    for word in alphabet:\n",
    "        if alphabet[word] > 2:\n",
    "            new_alphabet[word] = alphabet[word]\n",
    "    return new_alphabet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:00:50.183947Z",
     "start_time": "2024-05-27T01:00:50.177929Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": "alphabet = remove_words_with_count_below_2(initial_alphabet)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:00:54.511938Z",
     "start_time": "2024-05-27T01:00:54.006373Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "print(f\"Different words in alphabet: {len(alphabet)}\")",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:00:58.868739Z",
     "start_time": "2024-05-27T01:00:58.850942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different words in alphabet: 233563\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "word_c = {}\n",
    "for v in vectors:\n",
    "    for w in v.vector:\n",
    "        if w not in word_c:\n",
    "            word_c[w] = 1\n",
    "        else:\n",
    "            word_c[w] += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:02:20.712829Z",
     "start_time": "2024-05-27T01:01:02.823011Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def remove_weird_words(alphabet):\n",
    "    new_alphabet = {}\n",
    "    for word in alphabet:\n",
    "        if len(word) <= 20:\n",
    "            new_alphabet[word] = alphabet[word]\n",
    "    return new_alphabet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:02:26.291617Z",
     "start_time": "2024-05-27T01:02:26.270733Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "alphabet = remove_weird_words(alphabet)",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:02:33.899328Z",
     "start_time": "2024-05-27T01:02:33.704714Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "print(f\"Different words in alphabet: {len(alphabet)}\")",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:02:50.193382Z",
     "start_time": "2024-05-27T01:02:49.967049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different words in alphabet: 231286\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "ind = 0\n",
    "indexed_alphabet = {}\n",
    "for word in alphabet:\n",
    "    indexed_alphabet[word] = ind\n",
    "    ind += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:02:57.745698Z",
     "start_time": "2024-05-27T01:02:57.573656Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"data/alphabet.json\", \"w\", encoding=\"latin-1\") as f:\n",
    "    json.dump(indexed_alphabet, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:03:03.197611Z",
     "start_time": "2024-05-27T01:03:02.853059Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "for vec in vectors:\n",
    "    new_vector = {}\n",
    "    for word in vec.vector:\n",
    "        if word in indexed_alphabet:\n",
    "            new_vector[word] = vec.vector[word]\n",
    "    vec.vector = new_vector"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:04:31.346230Z",
     "start_time": "2024-05-27T01:03:07.954106Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"data/Bag_of_words.pickle\", \"wb\") as f:\n",
    "    for vec in vectors:\n",
    "        pickle.dump(vec, f)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-27T01:06:30.814409Z",
     "start_time": "2024-05-27T01:05:04.361389Z"
    }
   },
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
